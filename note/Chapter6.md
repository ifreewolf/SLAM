# 非线性优化

<B>主要目标</B>

> 1. 理解最小二乘法的含义和处理方式。
> 2. 理解高斯牛顿法(Gauss-Newton's method)、列文伯格-马夸尔特方法(Levenburg-Marquadt's method)等下降策略。
> 3. 学习Ceres库和g2o库的基本使用方法。

方程中的位姿可以由变换矩阵来描述，然后用李代数进行优化。观测方程由相机成像模型给出，其中内参是随相机固定的，而外参则是相机的位姿。

由于噪声的存在，运动方程和观测方程的等式必定不是精确成立的。尽管相机可以非常好地符合针孔模型，但遗憾的是，得到的数据通常是受各种未知噪声影响的。与其假设数据必须符合方程，不如讨论如何在有噪声的数据中进行准确的状态估计。

解决状态估计问题需要一定程度的最优化背景知识，本节将介绍基本的无约束非线性优化方法，同时介绍优化库g2o和Ceres的使用方式。

# 6.1 状态估计问题

## 6.1.1 批量状态估计与最大后验估计

SLAM模型由运动方程和观察方程构成构成：

$$
\left\{ \begin{aligned} x_l = f(x_{k-1}, u_k) + w_k \\ z_{k,j} = h(y_j, x_k) + v_{k,j} \end{aligned} \right. . \tag{6.1}
$$

> $x_k$是相机的位姿，用SE(3)来描述。观测方程就是针孔相机模型。

位姿变量$x_k$可以由$T_k \in SE(3)$表达，假设在$x_k$处对路标$y_j$进行了一次观测，对应到图像上的像素位置$z_{k,j}$，那么，观测方程可以表示成：

$$
sz_{k,j}=K(R_k y_j + t_k). \tag{6.2}
$$

> 其中$K$为相机内参，$s$为像素点的距离，也是$(R_k y_j + t_k)$的第三个分量。如果使用变换矩阵$T_k$描述位姿，那么路标点$y_j$必须以齐次坐标来描述，计算完成后要转换为非齐次坐标。

在运动和观测方程中，假设两个噪声项$w_k,v_{k,j}$满足零均值的高斯分布，像这样：

$$
w_k \sim \mathcal{N}(0, R_k), v_k \sim \mathcal{N}(0, Q_{k,j}). \tag{6.3}
$$

> 其中$\mathcal{N}$表示高斯分布，$0$表示零均值，$R_{k}, Q_{k,j}$为协方差矩阵。在这些噪声的影响下，希望通过带噪声的数据$z$和$u$推断位姿$x$和地图$y$（以及它们的概率分布），这就构成了一个状态估计问题。

处理这个状态估计问题的方法大致分成两种：1）在SLAM过程中，数据是随时间逐渐到来的，所以，我们应该持有一个当前时刻的估计状态，然后用新的数据来更新它，这种方式称为<B>增量/渐进</B>(incremental)的方法，或者叫滤波器。在历史上很长一段时间，研究者使用滤波器，尤其是扩展卡尔曼滤波器及其衍生方式求解它。2）另一种方式，则是把数据“攒”起来一并处理，这种方式称为<B>批量</B>(batch)的方法。例如，可以把$0$到$k$时刻所有的输入和观测数据都放一起，这样的输入和输出，如何估计整个$0$到$k$时刻的轨迹与地图呢？

增量方法仅关心<B>当前时刻</B>的状态估计$x_k$，而对之前的状态则不多考虑；相对地，批量方法可以在<B>更大的范围</B>达到最优化，被认为优于传统的滤波器，而成为当前视觉SLAM的主流方法。极端情况下，可以让机器人或无人机收集所有时刻的数据，再带回计算中心统一处理，这也正是SfM(Structure from Motion)的主流做法。这种极端情况不是实时的，不符合SLAM的运用场景，所以在SLAM中，实用的方法通常都是一些折衷的手段，例如，固定一些历史轨迹，仅对当前时刻附近的一些轨迹进行优化。

考虑批量方法，从$1$到$N$的所有时刻，并假设有$M$个路标点，定义所有时刻的机器人位姿和路标点坐标为：

$$
x = {x_1, ..., x_N}, \quad y = {y_1, ... , y_M}.
$$

> 用不带下标的$u$表示所有时刻的输入，$z$表示所有时刻的观测数据。对机器人状态的估计，从概率学的观点来看，就是已知输入数据$u$和观测数据$z$的条件下，求状态$x,y$的条件概率分布：

$$
P(x,y|z,u). \tag{6.4}
$$

当我们不知道控制输入，只有一张张的图像时，即只考虑观测方程带来的数据时，相当于估计$P(x,y|z)$的条件概率分布，此问题也称为SfM，即如何从许多图像中重建三维空间结构。

为了估计状态变量的条件分布，利用贝叶斯法则，有：

$$
P(x,y|z,u)=\frac{P(z,u|x,y)P(x,y)}{P(z,u)} \propto \underbrace{P(z,u|x,y)}_{似然} \underbrace{P(x,y)}_{先验}. \tag{6.5}
$$

贝叶斯法则左侧称为后验概率，右侧的$P(z|x)$称为似然(Likehood)，另一部分$P(x)$称为先验(Prior)。<B>直接求后验分布是困难的，但是求一个状态最优估计，使得在该状态下后验概率最大化</B>，则是可行的：

$$
(x,y)_{MAP}^{*} = \argmax P(x,y|z,u) = \argmax P(z,u|x,y) P(x,y). \tag{6.6}
$$

贝叶斯法则的分布部分与待估计的状态$x,y$无关，因而可以忽略。贝叶斯法则告诉我们，求解最大后验概率<B>等价于最大化似然和先验的乘积</B>。

> 如果不知道机器人位姿或路标，此时没有了先验，那么，可以求解<B>最大似然估计</B>(Maximize Likelihood Estimation, MLE)：

$$
(x,y)_{MLE}^{*} = \argmax P(z, u|x, y). \tag{6.7}
$$

> 直观地讲，似然是指“在现在的位姿，可能产生怎样的观测数据”。由于我们知道观测数据，所以最大似然估计可以理解成：“<B>在什么样的状态下，最可能产生现在观测到的数据</B>”。这就是最大似然估计的直观意义。

## 6.1.2 最小二乘的引出

在高斯分布的假设下，最大似然能够有较简单的形式。回顾观测模型，对于某一次观测：

$$
z_{k,j} = h(y_j, x_k) + v_{k,j},
$$

由于架设了噪声项$v_k \sim \mathcal{N}(0,Q_{k,j})$，所以观测数据的条件概率为

$$
P(z_{j,k}|x_k,y_j) = N(h)
$$

它依然是一个高斯分布。考虑单次观测的最大似然估计，可以使用<B>最小化负对数</B>来求一个高斯分布的最大似然。

高斯分布在负对数下有较好的数学形式，考虑任意高维高斯分布$x \sim \mathcal{N}(\mu, \Sigma)$，它的概率密度函数展开形式为

$$
P(x) = \frac{1}{\sqrt{(2\pi)^N \det(\Sigma)}}\exp\left( -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \right). \tag{6.8}
$$

对其取负对数，则变为

$$
-\ln(P(x)) = \frac{1}{2}\ln{\left( (2\pi)^N\det(\Sigma) \right)} + \frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu). \tag{6.9}
$$

因为对数函数是单调递增的，所以对原函数求最大化相当于对负对数求最小化。在最小化上式的$x$时，第一项与$x$无关，可以略去。于是，只要最小化右侧的二次型项，就得到了对状态的最大似然估计。代入SLAM的观测模型，相当于在求：

$$
\begin{aligned}
(x_k,y_j)^* &= \argmax \mathcal{N}(h(y_j,x_k), Q_{k,j}) \\
&=\argmin \left( (z_{k,j} - h(x_k,y_j))^T Q_{k,j}^{-1}(z_{k,j}-h(x_k,y_j)) \right).
\end{aligned} \tag{6.10}
$$

