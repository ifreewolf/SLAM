# 非线性优化

<B>主要目标</B>

> 1. 理解最小二乘法的含义和处理方式。
> 2. 理解高斯牛顿法(Gauss-Newton's method)、列文伯格-马夸尔特方法(Levenburg-Marquadt's method)等下降策略。
> 3. 学习Ceres库和g2o库的基本使用方法。

方程中的位姿可以由变换矩阵来描述，然后用李代数进行优化。观测方程由相机成像模型给出，其中内参是随相机固定的，而外参则是相机的位姿。

由于噪声的存在，运动方程和观测方程的等式必定不是精确成立的。尽管相机可以非常好地符合针孔模型，但遗憾的是，得到的数据通常是受各种未知噪声影响的。与其假设数据必须符合方程，不如讨论如何在有噪声的数据中进行准确的状态估计。

解决状态估计问题需要一定程度的最优化背景知识，本节将介绍基本的无约束非线性优化方法，同时介绍优化库g2o和Ceres的使用方式。

# 6.1 状态估计问题

## 6.1.1 批量状态估计与最大后验估计

SLAM模型由运动方程和观察方程构成构成：

$$
\left\{ \begin{aligned} x_l = f(x_{k-1}, u_k) + w_k \\ z_{k,j} = h(y_j, x_k) + v_{k,j} \end{aligned} \right. . \tag{6.1}
$$

> $x_k$是相机的位姿，用SE(3)来描述。观测方程就是针孔相机模型。

位姿变量$x_k$可以由$T_k \in SE(3)$表达，假设在$x_k$处对路标$y_j$进行了一次观测，对应到图像上的像素位置$z_{k,j}$，那么，观测方程可以表示成：

$$
sz_{k,j}=K(R_k y_j + t_k). \tag{6.2}
$$

> 其中$K$为相机内参，$s$为像素点的距离，也是$(R_k y_j + t_k)$的第三个分量。如果使用变换矩阵$T_k$描述位姿，那么路标点$y_j$必须以齐次坐标来描述，计算完成后要转换为非齐次坐标。

在运动和观测方程中，假设两个噪声项$w_k,v_{k,j}$满足零均值的高斯分布，像这样：

$$
w_k \sim \mathcal{N}(0, R_k), v_k \sim \mathcal{N}(0, Q_{k,j}). \tag{6.3}
$$

> 其中$\mathcal{N}$表示高斯分布，$0$表示零均值，$R_{k}, Q_{k,j}$为协方差矩阵。在这些噪声的影响下，希望通过带噪声的数据$z$和$u$推断位姿$x$和地图$y$（以及它们的概率分布），这就构成了一个状态估计问题。

处理这个状态估计问题的方法大致分成两种：1）在SLAM过程中，数据是随时间逐渐到来的，所以，我们应该持有一个当前时刻的估计状态，然后用新的数据来更新它，这种方式称为<B>增量/渐进</B>(incremental)的方法，或者叫滤波器。在历史上很长一段时间，研究者使用滤波器，尤其是扩展卡尔曼滤波器及其衍生方式求解它。2）另一种方式，则是把数据“攒”起来一并处理，这种方式称为<B>批量</B>(batch)的方法。例如，可以把$0$到$k$时刻所有的输入和观测数据都放一起，这样的输入和输出，如何估计整个$0$到$k$时刻的轨迹与地图呢？

增量方法仅关心<B>当前时刻</B>的状态估计$x_k$，而对之前的状态则不多考虑；相对地，批量方法可以在<B>更大的范围</B>达到最优化，被认为优于传统的滤波器，而成为当前视觉SLAM的主流方法。极端情况下，可以让机器人或无人机收集所有时刻的数据，再带回计算中心统一处理，这也正是SfM(Structure from Motion)的主流做法。这种极端情况不是实时的，不符合SLAM的运用场景，所以在SLAM中，实用的方法通常都是一些折衷的手段，例如，固定一些历史轨迹，仅对当前时刻附近的一些轨迹进行优化。

考虑批量方法，从$1$到$N$的所有时刻，并假设有$M$个路标点，定义所有时刻的机器人位姿和路标点坐标为：

$$
x = {x_1, ..., x_N}, \quad y = {y_1, ... , y_M}.
$$

> 用不带下标的$u$表示所有时刻的输入，$z$表示所有时刻的观测数据。对机器人状态的估计，从概率学的观点来看，就是已知输入数据$u$和观测数据$z$的条件下，求状态$x,y$的条件概率分布：

$$
P(x,y|z,u). \tag{6.4}
$$

当我们不知道控制输入，只有一张张的图像时，即只考虑观测方程带来的数据时，相当于估计$P(x,y|z)$的条件概率分布，此问题也称为SfM，即如何从许多图像中重建三维空间结构。

为了估计状态变量的条件分布，利用贝叶斯法则，有：

$$
P(x,y|z,u)=\frac{P(z,u|x,y)P(x,y)}{P(z,u)} \propto \underbrace{P(z,u|x,y)}_{似然} \underbrace{P(x,y)}_{先验}. \tag{6.5}
$$

贝叶斯法则左侧称为后验概率，右侧的$P(z|x)$称为似然(Likehood)，另一部分$P(x)$称为先验(Prior)。<B>直接求后验分布是困难的，但是求一个状态最优估计，使得在该状态下后验概率最大化</B>，则是可行的：

$$
(x,y)_{MAP}^{*} = \argmax P(x,y|z,u) = \argmax P(z,u|x,y) P(x,y). \tag{6.6}
$$

贝叶斯法则的分布部分与待估计的状态$x,y$无关，因而可以忽略。贝叶斯法则告诉我们，求解最大后验概率<B>等价于最大化似然和先验的乘积</B>。

> 如果不知道机器人位姿或路标，此时没有了先验，那么，可以求解<B>最大似然估计</B>(Maximize Likelihood Estimation, MLE)：

$$
(x,y)_{MLE}^{*} = \argmax P(z, u|x, y). \tag{6.7}
$$

> 直观地讲，似然是指“在现在的位姿，可能产生怎样的观测数据”。由于我们知道观测数据，所以最大似然估计可以理解成：“<B>在什么样的状态下，最可能产生现在观测到的数据</B>”。这就是最大似然估计的直观意义。

## 6.1.2 最小二乘的引出

在高斯分布的假设下，最大似然能够有较简单的形式。回顾观测模型，对于某一次观测：

$$
z_{k,j} = h(y_j, x_k) + v_{k,j},
$$

由于架设了噪声项$v_k \sim \mathcal{N}(0,Q_{k,j})$，所以观测数据的条件概率为

$$
P(z_{j,k}|x_k,y_j) = N(h)
$$

它依然是一个高斯分布。考虑单次观测的最大似然估计，可以使用<B>最小化负对数</B>来求一个高斯分布的最大似然。

高斯分布在负对数下有较好的数学形式，考虑任意高维高斯分布$x \sim \mathcal{N}(\mu, \Sigma)$，它的概率密度函数展开形式为

$$
P(x) = \frac{1}{\sqrt{(2\pi)^N \det(\Sigma)}}\exp\left( -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu) \right). \tag{6.8}
$$

对其取负对数，则变为

$$
-\ln(P(x)) = \frac{1}{2}\ln{\left( (2\pi)^N\det(\Sigma) \right)} + \frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu). \tag{6.9}
$$

因为对数函数是单调递增的，所以对原函数求最大化相当于对负对数求最小化。在最小化上式的$x$时，第一项与$x$无关，可以略去。于是，只要最小化右侧的二次型项，就得到了对状态的最大似然估计。代入SLAM的观测模型，相当于在求：

$$
\begin{aligned}
(x_k,y_j)^* &= \argmax \mathcal{N}(h(y_j,x_k), Q_{k,j}) \\
&=\argmin \left( (z_{k,j} - h(x_k,y_j))^T Q_{k,j}^{-1}(z_{k,j}-h(x_k,y_j)) \right).
\end{aligned} \tag{6.10}
$$

该式等价于最小化噪声项(即误差)的一个二次型。这个二次型称为<B>马哈拉诺比斯距离</B>(Mahalanobis distance)，又叫马氏距离。它也可以看成由$Q_{k,j}^{-1}$加权之后的欧氏距离(二次范数)，这里$Q_{k,j}^{-1}$也叫<B>信息矩阵</B>，即高斯分布协方差矩阵之逆。

现在考虑批量时刻的数据，假设各个时刻的输入和观测是相互独立的，意味着各个输入之间是独立的，各个观测之间是独立的，并且输入和观测也是独立的。对联合分布进行因式分解：

$$
P(z,u|x,y)=\prod_{k}P(u_k|x_{k-1},x_k)\prod_{k,j}P(z_{k,j}|x_k,y_j), \tag{6.11}
$$

这说明可以独立地处理各时刻的运动和观测。定义各次输入和观测数据于模型之间的误差：

$$
e_{u,k}=x_k - f(x_{k-1},u_k) \\
e_{z,j,k}=z_{k,j} - h(x_{k},y_j), \tag{6.12}
$$

最小化所有时刻估计值与真实读数之间的马氏距离，等价于求最大似然估计。负对数允许我们把乘积变成求和：

$$
\min J(x,y) = \sum_k e_{u,k}^{T} R_{k}^{-1} e_{u,k} + \sum_k \sum_j e_{z,k,j}^{T} Q_{k,j}^{-1} e_{z,k,j}. \tag{6.13}
$$

这样就得到了一个<B>最小二乘问题</B>(Least Square Problem)，它的解等价于状态的最大似然估计。直观上看，由于噪声的存在，当我们把估计的轨迹与地图代入SLAM的运动、观测方程中时，它们并不会完美地成立。这时怎么办？

我们对状态的估计值进行微调，使得整体的误差下降一些。当然，这个下降也有限度，它一般会到达一个<B>极小值</B>。这就是典型的非线性优化的过程。

观察式(6.13)，会发现SLAM中的最小二乘问题具有一些特定的结构：

- 首先，整个问题的目标函数由许多个误差的(加权的)二次型组成。虽然总体的状态变量维数很高，但每个误差项都是简单的，仅与一两个状态变量有关。例如，运动误差只与$x_{k-1},x_k$有关，观测误差只与$x_k,y_j$有关。这种关系会让整个问题有一种<B>稀疏</B>的形式。
- 齐次，如果使用李代数表示增量，则该问题是<B>无约束</B>的最小二乘问题。但如果用旋转矩阵/变换矩阵描述位姿，则会引入旋转矩阵自身的约束，即需在问题中加入$s.t. R^TR=I$且$\det(R)=1$这样令人头大的条件。额外的约束会使优化变得更困难。这体现了李代数的优势。
- 最后，我们使用了二次型度量误差。误差的分布将影响此项在整个问题中的权重。例如，某次的观测非常准确，那么协方差矩阵就会“小”，而信息矩阵就会“大”，所以这个误差项会在整个问题中占有较高的权重。
  
## 6.1.3 例子：批量状态估计

考虑一个非常简单的离散时间系统：

$$
\begin{aligned}
&x_k = x_{k-1} + u_k + w_k, \qquad &w_k \sim \mathcal{N}(0, Q_k) \\
&z_k = x_k + n_k, \qquad &n_k \sim \mathcal{N}(0, R_k) \tag{6.14}
\end{aligned}
$$

这可以表达一辆沿$x$轴前进或后退的汽车。第一个公式为运动方程，$u_k$为输入，$w_k$为噪声；第二个公式为观测方程，$z_k$为对骑车车位置的测量。取时间$k=1,...,3$，现希望根据已有的$v,y$进行状态估计。设初始状态$x_0$已知。下面来推导批量状态的最大似然估计。

首先，令批量状态变量为$x=[x_0,x_1,x_2,x_3]^T$，令批量观测为$z=[z_1,z_2,z_3]^T$，按同样方式定义$u=[u_1,u_2,u_3]^T$。按照之前的推导，我们知道最大似然估计为

$$
\begin{aligned}
x_{map}^{*} &= \argmax P(x|u, z) = \argmax P(u,z|x) \\
&= \prod_{k=1}^3 P(u_k|x_{k-1},x_k) \prod_{k=1}^3 P(z_k | x_k),
\end{aligned} \tag{6.15}
$$

对于具体的每一项，比如运动方程，我们知道：

$$
P(u_k|x_{k-1},x_k)=\mathcal{N}(x_k - x_{k-1}, Q_k), \tag{6.16}
$$

观测方程也是类似的：

$$
P(z_k | x_k) = \mathcal{N}(x_k,R_k). \tag{6.17}
$$

根据这些方法，就能实际地解决上面的批量状态估计问题。根据之前的叙述，可以构建误差变量：

$$
e_{u,k} = x_k - x_{k-1} - u_k, \quad e_{z,k} = z_k - x_k, \tag{6.18}
$$

于是最小二乘的目标函数为

$$
\min \sum_{k=1}^{3} e_{u,k}^{T} Q_{k}^{-1} e_{u,k} + \sum_{k=1}^3 e_{z,k}^{T} R_{k}^{-1} e_{z,k}. \tag{6.19}
$$

此外，这个系统是线性系统，我们可以很容易地将它写成向量形式。定义向量$y=[u,z]^T$，那么可以写出矩阵$H$，使得

$$
y - Hx = e \sim \mathcal{N}(0, \Sigma). \tag{6.20}
$$

那么：

$$
H = \frac{\begin{bmatrix} 1 & -1 & 0 & 0 \\ 0 & 1 & -1 & 0 \\ 0 & 0 & 1 & -1 \end{bmatrix}}{\begin{bmatrix} 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix}}. \tag{6.21}
$$

且$\Sigma = diag (Q_1, Q_2, Q_3, R_1, R_2, R_3)$。整个问题可以写成

$$
x_{map}^* = \argmin e^T \Sigma^{-1}e, \tag{6.22}
$$

---

# 6.2 非线性最小二乘

先考虑一个简单的最小二乘问题：

$$
\min_{x} F(x) = \frac{1}{2}\lVert f(x) \rVert_2^2. \tag{6.24}
$$

其中，自变量$x \in \mathbb{R}^n$，$f$是任意标量非线性函数$f(x):\mathbb{R}^n \mapsto \mathbb{R}$。注意这里的系数$\frac{1}{2}$是无关紧要的。显然，如果$f$是个数学形式上很简单的函数，那么该问题可以用解析形式来求。令目标函数的导数为零，然后求解$x$的最优值，就和求二元函数的极值一样：

$$
\frac{dF}{dx} = 0. \tag{6.25}
$$

解此方程，就得到了导数为零处的极值。它们可能是极大、极小或鞍点处的值，只要逐个比较它们的函数值大小即可。这个方程是否容易求解，取决于$f$导函数的形式。如果$f$为简单的线性函数，那么这个问题就是简单的线性最小二乘问题，但是有些导函数形式复杂，使得该方程可能不容易求解。求解这个方程选哟我们知道关于目标函数的全局性质，而通常这是不大可能的。对于不方便求解的最小二乘问题，我们可以用迭代的方式，从一个初始值出发，不断地更新当前的优化变量，使目标函数下降。具体步骤可列写如下：

1. 给定某个初始值$x_0$。
2. 对于第$k$次迭代，寻找一个增量$\Delta x_k$，使得$\lVert f(x_k + \Delta x_k) \rVert^2$达到极小值。
3. 若$\Delta x_k$足够小，则停止。
4. 否则，令$x_{k+1}=x_k + \Delta x_k$，返回第2步。


这让求解导函数为零的问题变成了一个不断寻找下降增量$\Delta x_k$的问题，由于可以对$f$进行线性化，增量的计算将简单很多。当函数下降直到增量非常小的时候，就认为算法收敛，目标函数达到了一个极小值。

在这个过程中，问题在于如何找到每次迭代点的增量，而这是一个局部的问题，我们只需要关心$f$在迭代处的局部性质而非全局性质。

## 6.2.1 一阶和二阶梯度法

现在考虑第$k$次迭代，假设我们在$x_k$处，想要寻找增量$\Delta x_k$，那么最直观的方式是将目标函数在$x_k$附近进行泰勒展开：

$$
F(x_k + \Delta x_k) \approx F(x_k) + J(x_k)^T\Delta x_k + \frac{1}{2}\Delta x_k^T H(x_k) \Delta x_k. \tag{6.26}
$$

其中$J(x_k)$是$F(x)$关于$x$的一阶导数【也叫梯度、雅可比比(Jacobian)矩阵】，$H$则是二阶导数【<B>海塞(Hessian)</B>矩阵】，它们都在$x_k$处取值。可以保留泰勒展开的一阶或二阶项，那么对应的求解方法则称为一阶梯度或二阶梯度法。如果保留一阶梯度，那么取增量为反向的梯度，即可保证函数下降：

$$
\Delta x^* = -J(x_K). \tag{6.27}
$$

这只是一个方向，通常还需要指定一个步长$\lambda$。步长可以根据一定的条件来计算，<B>最速下降法</B>，只要沿着反向梯度方向前进，在一阶(线性)的近似下，目标函数必定会下降。

如果保留二阶梯度信息，此时增量方程为：

$$
\Delta x^* = \argmin \left( F(x) + J(x)^T \Delta x + \frac{1}{2}\Delta x^T H \Delta x \right). \tag{6.28}
$$

右侧只含$\Delta x$的零次、一次和二次项。求右侧等式关于$\Delta x$的导数并令它为零，得到：

$$
J + H \Delta x = 0 \Rightarrow H\Delta x = -J. \tag{6.29}
$$

求解这个线性方程，就得到了增量。该方法又称为<B>牛顿法</B>。

一阶和二阶梯度法都十分直观，只要把函数在迭代点附近进行泰勒展开，并针对更新量做最小化即可。事实上，我们用一个一次或二次的函数近似了原函数，然后用近似函数的最小值来猜测原函数的极小值。只要原目标函数局部看起来像一次或二次函数，这类算法就是成立的。不过这两种方法也存在它们自身的问题。最速下降法过于贪心，容易走出锯齿路线，反而增加了迭代次数。而牛顿法则需要计算目标函数的$H$矩阵，这在问题规模较大时非常困难，我们通常倾向于避免$H$的计算。对于一般的问题，一些拟牛顿法可以得到较好的结果，而对于最小二乘问题，还有几类更实用的方法：<B>高斯牛顿法和列文伯格-马奈尔特方法</B>。

### 6.2.2 高斯牛顿法

高斯牛顿法中采用的近似二阶泰勒展开只能在展开点附近有较好的近似效果，很自然想到应该给$\Delta x$添加一个范围，称为<B>信赖区域</B>(Trust Region)。这个范围定义了在什么情况下二阶近似是有效的，这类方法也称为<B>信赖区域方法</B>(Trust Region Method)。在信赖区域里，我们认为近似是有效的；出了这个区域，近似可能会出问题。

如何确定这个信赖区域的范围呢？一个较好的方法是根据我们的近似模型跟实际函数之间的差异来确定：如果差异小，说明近似效果好，可以扩大近似的范围；反之，如果差异大，就缩小近似的范围。我们定义一个指标$\rho$来刻画近似的好坏程度：

$$
\rho = \frac{f(x + \Delta x) - f(x)}{J(x)^T \Delta x}. \tag{6.34}
$$

$\rho$的分子是实际函数下降的值，分母是近似模型下降的值。如果$\rho$接近于1，则近似是好的。如果$\rho$太小，说明实际减小的值远少于近似减小的值，则认为近似比较差，需要缩小近似范围。反之，如果$\rho$比较大，则说明实际下降的比预计的更大，我们可以放大近似范围。

于是，我们构建一个改良的非线性优化框架，该框架会比高斯牛顿法有更好的效果：

1. 给定初始值$x_0$，以及初始化半径$\mu$。
2. 对于第$k$次迭代，在高斯牛顿法的基础上加上信赖区域，求解：
$$
\min_{\Delta x_k}\frac{1}{2}\lVert f(x_k) + J(x_k)^T\Delta x_k \rVert^2, \quad \lVert D\Delta x_k \rVert^2 \le \mu, \tag{6.35}
$$
> 其中，$\mu$是信赖区域的半径，$D$为系数矩阵。

3. 按式(6.34)计算$\rho$。
4. 若$\rho > \frac{3}{4}$，则设置$\mu=2\mu$。
5. 若$\rho < \frac{1}{4}$，则设置$\mu=0.5\mu$。
6. 如果$\rho$大于某阈值，则认为近似可行。令$x_{k+1}=x_k + \Delta x_k$。
7. 判断算法是否收敛。如不收敛则返回第2步，否则结束。


这里近似范围扩大的倍数和阈值都是经验值，可以替换成别的数值。在式(6.35)中，把增量限定于一个半径为$\mu$的球中，认为只在这个球内才是有效的。带上$D$之后，这个球可以看成一个椭圆球。在列文伯格提出的优化方法中，把$D$取成单位矩阵$I$，相当于直接把$\Delta x_k$约束在一个球中。随后，马夸尔提出将$D$取成非负对角阵--实际中通常用$J^TJ$的对角元素平方根，使得在梯度小的维度上约束范围更大一些。

无论如何，在列文伯格-马奈尔特优化中，都需要解式(6.35)那样一个子问题来获得梯度。这个子问题是带不等式约束的优化问题，用拉格朗日乘子把约束项放到目标函数中，构成拉格朗日函数：

$$
\mathcal{L}(\Delta x_k, \lambda) = \frac{1}{2}\lVert f(x_k) + J(x_k)^T\Delta x_k \rVert^2 + \frac{\lambda}{2}\left( \lVert D\Delta x_k \rVert^2 - \mu \right). \tag{6.36}
$$

这里$\lambda$为拉格朗日乘子，类似于高斯牛顿法中的做法，令该拉格朗日函数关于$\Delta x$的导数为零，它的核心仍是计算增量的线性方程：

$$
(H + \lambda D^TD)\Delta x_k =g. \tag{6.37}
$$

可以看到，相比于高斯牛顿法，增量方程多了一项$\lambda D^TD$。如果考虑它的简化形式，即$D=I$，那么相当于求解：

$$
(H+\lambda I)\Delta x_k =g.
$$

一方面，当参数$\lambda$较小时，$H$占主要地位，这说明二次近似模型在该范围内是比较好的，列文伯格-马奈尔特方法更接近于高斯牛顿法。另一方面，当$\lambda$比较大时，$\lambda I$占据主要地位，列文伯格-马奈尔特更接近于一阶梯度下降法(即最速下降)，这说明附近的二次近似不够好。列文伯格-马奈尔特方法的求解方式，可在一定程度上避免线性方程组的系数矩阵的非奇异和病态问题，提供更稳定、更准确的增量$\Delta x$。


