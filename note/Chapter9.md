# 第9讲 后端1

<div style="border: 1px solid black;">
<B>主要目标</B>

1. 理解后端的概念。
2. 理解以EKF为代表的滤波器后端的工作原理。
3. 理解非线性优化的后端，明白稀疏性是如何利用的。
4. 使用g2o和Ceres实际操作后端优化。
</div>

前端视觉里程计能给出一个短时间内的轨迹和地图，但由于不可避免的误差累积，这个地图在长时间内是不准确的。所以，在视觉里程计的基础上，还希望构建一个尺度、规模更大的优化问题，以考虑长时间内的最优轨迹和地图。不过，考虑到精度与性能的平衡，实际中存在着许多不同的做法。

## 9.1 概述

### 9.1.1 状态估计的概率解释

第2讲中提到，视觉里程计只有短暂的记忆，而我们希望整个运动轨迹在较长时间内都能保持最优的状态。在后端优化中，通常考虑一段更长时间内(或所有时间内)的状态估计问题，而且不仅使用过去的信息更新自己的状态，也会用未来的信息来更新，这种处理方式称为“<B>批量的</B>”(Batch)。否则，如果当前的状态只由过去的时刻决定，甚至只由前一个时刻决定，则称为“<B>渐进的</B>”(Incremental)。

已经知道SLAM过程可以由运动方程和观测方程来描述，那么，假设在$t=0$到$t=N$的时间内，有位姿$x_0$到$x_N$，并且有路标$y_1,\cdots,y_M$。按照之前的写法，运动和观测方程为

$$
\left\{ 
    \begin{array}{l}
        x_k = f(x_{k-1}, u_k) + w_k \\
        z_{k,j} = h(y_j,x_k) + v_{k,j}
    \end{array}
\right. k = 1,...,N,j = 1, ... , M. \tag{9.1}
$$

注意以下几点：

1. 观测方程中，只有当$x_k$看到了$y_j$时，才会产生观测数据，否则就没有，事实上，在一个位置通常只能看到一小部分路标。而且，由于视觉SLAM特征点数量众多，所以实际中观测方程的数量会远远大于运动方程。
2. 我们可能没有测量运动的装置，也可能没有运动方程。在这个情况下，有若干个处理方式：认为确实没有运动方程，或假设相机不动，或假设相机匀速运动。这几种方式都是可行的。在没有运动方程的情况下，整个优化问题就只由许多个观测方程组成。这就非常类似于SfM问题，相当于我们通过一组图像来恢复运动和结构。不同的是，SLAM中的图像有时间上的先后顺序，而SfM中允许使用完全无关的图像。

我们知道每个方程都受噪声影响，所以要把这里的位姿$x$和路标$y$看成<B>服从某种概率分布的随机变量</B>，而不是单独的一个数。因此，我们关心的问题就变成：当我们拥有某些运动数据$u$和观测数据$z$时，如何确定状态变量$x,y$的分布？进而，如果得到了新时刻的数据，它们的分布又将发生怎样的变化？在比较常见且合理的情况下，我们假设状态量和噪声项服从高斯分布--这意味着在程序中只需要存储它们的均值和协方差矩阵即可。均值可看作对变量最优值的估计，而协方差矩阵则度量了它的不确定性。那么，问题就转变为：当存在一些运动数据和观测数据时，我们如何估计状态量的高斯分布？

我们依然设身处地地扮演小萝卜，只有运动方程时，相当于我们蒙着眼睛在一个未知的地方走路。尽管我们知道自己每一步走了多远，但是随着时间流逝，我们越来越不确定自己的位置--内心也就越不安。这说明当输入数据受噪声影响时，<B>误差是逐渐累积的</B>，我们对位置房方差的估计将越来越大。但是，当我们睁开眼睛时，由于能够不断地观测到外部场景，使得位置估计的不确定性变小。如果用椭圆或椭球直观地表达协方差阵，那么这个过程有点像是在手机地图软件中走路的感觉。以下图为例，当没有观测数据时，这个圆会随着运动越来越大；而如果有正确的观测数据，圆会缩小至一定的大小，保持稳定。

<div align=center>
    <img src="./image/不确定性的描述.png" />
</div>

> 左侧：只有运动方程时，由于下一时刻的位姿是在上一时刻的基础上添加了噪声，所以不确定性越来越大。右侧：存在路标点时，不确定性会明显减小。


在第6讲中，介绍了最大似然估计，提到<B>批量状态估计问题可以转化为最大似然估计问题，并使用最小二乘法进行求解</B>。在本节中，将探讨如何将该结论应用于渐进式问题，得到一些经典的结论。同时，在视觉SLAM里，最小二乘法又有何特殊的结构。

由于位姿何路标点都是待估计的变量，改变记号，令$x_k$为$k$时刻的所有未知量。它包含了当前时刻的相机位姿与$m$个路标点。在这种记号的意义下(虽然与之前稍有不同，但含义是清楚的)，写成

$$
x_k \overset{def}{=} {x_k,y_1,...,y_m}. \tag{9.2}
$$

同时，把$k$时刻的所有观测记作$z_k$。于是，运动方程与观测方程的形式可写得更简洁。这里不会出现$y$，但我们心里要明白这时$x$中已经包含了之前的$y$:

$$
\left\{
    \begin{array}{l}
        x_k = f(x_{k-1},u_k) + w_k \\
        z_k = h(x_k) + v_k
    \end{array}
 \right. k = 1,...,N. \tag{9.3}
$$

现在考虑第$k$时刻的情况，我们希望用过去$0$到$k$中的数据来估计现在的状态分布：

$$
P(x_k|x_0,u_{1:k},z_{1:k}). \tag{9.4}
$$

下标$0:k$表示从$0$时刻到$k$时刻的所有数据。请注意，$z_k$表示所有在$k$时刻的观测数据，它可能不止一个，只是这种记法更方便。同时，$x_k$实际上和$x_{k-1},x_{k-2}$这些量有关，但是此式没有显式地将它们写出来。

下面看看如何对状态进行估计，按照贝叶斯法则，把$z_k$与$x_k$交换位置，有

$$
P(x_k|x_0,u_{1:k},z_{1:k}) \propto P(z_k|x_k)P(x_k|x_0,u_{1:k},z_{1:k-1}). \tag{9.5}
$$

第一项称为<B>似然</B>，第二项称为<B>先验</B>。似然由观测方程给定，而先验部分，当前状态$x_k$是基于过去所有的状态估计得来的。至少，它会受$x_{k-1}$影响，于是以$x_{k-1}$时刻为条件概率展开：

$$
P(x_k|x_0,u_{1:k},z_{1:k-1}) = \int P(x_k|x_{k-1},x_0,u_{1:k},z_{1:k-1}) P(x_{k-1}|x_0,u_{1:k},z_{1:k-1})dx_{k-1}. \tag{9.6}
$$

如果考虑更久之前的状态，也可以继续对此式进行展开，但现在我们只关心$k$时刻和$k-1$时刻的情况。至此，我们给出了贝叶斯估计，因为上式还没有具体的概率分布形式，所以没法实际操作它。对这一步的后续处理，方法上产生了一些分歧。大体上讲，存在若干种选择：一种方法是假设<B>马尔可夫性</B>，简单的一阶马氏性认为，$k$时刻状态只与$k-1$时刻状态有关，而与再之前的无关。如果做出这样的假设，我们就会得到以<B>扩展卡尔曼滤波</B>(EKF)为代表的滤波器方法。在滤波方法中，我们会从某时刻的状态估计，推导到下一个时刻。另一种方法是依然考虑$k$时刻状态与之前<B>所有</B>状态的关系，此时将得到<B>非线性优化</B>为主体的优化框架。目前，视觉SLAM的主流为非线性优化方法。

### 9.1.2 线性系统和KF

首先来看滤波器模型，当我们假设了马尔可夫性，从数学角度会发生哪些变化呢？首先，当前时刻状态只和上一个时刻有关，式(9.6)中右侧第一部分可进一步简化：

$$
P(x_k|x_{k-1},x_0,u_{1:k},z_{1:k-1})=P(x_k|x_{k-1},u_k). \tag{9.7}
$$

这里，由于$k$时刻状态与$k-1$之前的无关，所以就简化成只与$x_{k-1}$和$u_k$有关的形式，与$k$时刻的运动方程对应。第二部分可简化为

$$
P(x_{k-1}|x_0,u_{1:k},z_{1:k-1}) = P(x_{k-1}|x_0,u_{1:k-1},z_{1:k-1}). \tag{9.8}
$$

考虑到$k$时刻的输入量$u_k$与$k-1$时刻的状态无关，所以把$u_k$拿掉。可以看到，这一项实际上是$k-1$时刻的状态分布。于是，这一系列方程说明，我们实际在做的是“如何把$k-1$时刻的状态分布推导至$k$时刻”这样一件事。

也就是说，在程序运动期间，我们只要维护一个状态量，对它不断地进行迭代和更新即可。如果假设状态量服从高斯分布，那么我们只需考虑维护状态量的均值和协方差即可。可以想象成小萝卜上的定位系统一直在向外输出两个定位信息：一是自己的位姿，二是自己的不确定性。实际中往往也是如此。

我们从形式最简单的线性高斯系统开始，最后得到卡尔曼滤波器。明确了起点和终点之后，再来考虑中间的路线。线性高斯系统是指，运动方程和观测方程可以由线性方程来描述：

$$
\left\{
    \begin{array}{l}
        x_k = A_k x_{k-1} + u_k + w_k \\
        z_k = C_k x_k + v_k
    \end{array} k = 1,...,N. \tag{9.9}
\right.
$$

并假设所有的状态和噪声均满足高斯分布。记这里的噪声服从零均值高斯分布：

$$
w_k \sim N(0,R). \quad v_k \sim N(0, Q). \tag{9.10}
$$

现在，利用马尔可夫性，假设我们知道了$k-1$时刻的后验(在$k-1$时刻看来)状态估计$\hat{x}_{k-1}$及其协方差$\hat{P}_{k-1}$，现在要根据$k$时刻的输入和观测数据，确定$x_k$的后验分布。为区分推导中的先验和后验，我们在记号上做一点区别：以<B>上帽子$\hat{x}_k$表示后验，以下帽子$\check{x}_k$表示先验分布</B>。

卡尔曼滤波器的第一步，通过运动方程确定$x_k$的先验分布。这一步是线性的，而高斯分布的线性变换仍是高斯分布。所以，显然有

$$
P(x_k|x_0,u_{1:k},z_{1:k-1}) = N\left( A_k \hat{x}_{k-1} + u_k, A_k \hat{P}_{k-1} A_k^T + R \right). \tag{9.11}
$$

这一步称为<B>预测</B>(Predict)。它显示了如何从上一个时刻的状态，根据输入信息(但是有噪声)推断当前时刻的状态分布。这个分布也就是先验。记：

$$
\check{x}_k = A_k \hat{x}_{k-1} + u_k, \quad \check{P}_k = A_k \hat{P}_{k-1}A_k^T + R. \tag{9.12}
$$

这非常自然，一方面，显然这一步状态的不确定度要变大，因为系统中添加了噪声。另一方面，由观测方程，可以计算在某个状态下应该产生怎样的观测数据：

$$
P(z_k|x_k) = N(C_k x_k, Q). \tag{9.13}
$$

为了得到后验概率，我们想要计算它们的乘积，也就是由式(9.5)给出的贝叶斯公式。然后，虽然我们知道最后会得到一个关于$x_k$的高斯分布，但计算上是有一点点麻烦的，先把结果设为$x_k \sim N(\hat{x}_k, \hat{P}_k)$，那么：

$$
N(\hat{x}_k, \hat{P}_k) = \eta N(C_k x_k, Q) \cdot N(\check{x}_k, \check{P}_k). \tag{9.14}
$$

我们已经知道等式两侧都是高斯分布，那就只需比较指数部分，无须理会高斯分布前面的因子部分。指数部分很像是一个二次型的配方，来推导一下。首先把指数部分展开，有

$$
(x_k - \hat{x}_k)^T \hat{P}_k^{-1} (x_k - \hat{x}_k) = (z_k - C_k x_k)^T Q^{-1} (z_k - C_k x_k) + (x_k - \check{x}_k)^T \check{P}_k^{-1}(x_k - \check{x}_k). \tag{9.15}
$$

为了求左侧的$\hat{x}_k$和$\hat{P}_k$，把两边展开，并比较$x_k$的二次和一次系数。对于二次系数，有

$$
\hat{P}_k^{-1} = C_k^T Q^{-1} C_k + \check{P}_k^{--1}. \tag{9.16}
$$

该式给出了协方差的计算过程。为了便于后面列写式子，定义一个中间变量：

$$
K = \hat{P}_k C_k^T Q^{-1}. \tag{9.17}
$$

根据此定义，在式(9.16)的左右各乘$\hat{P}_k$，有

$$
I = \hat{P}_k C_k^T Q^{-1} C_k + \hat{P}_k \check{P}_k^{-1} = K C_k + \hat{P}_k \check{P}_k^{-1}. \tag{9.18}
$$

于是有

$$
\hat{P}_k = (I - K C_k) \check{P}_k. \tag{9.19}
$$

然后比较一次项的系数，有

$$
-2\hat{x}_k^T \hat{P}_k^{-1} x_k = -2 z_k^T Q^{-1} C_k x_k - 2 \check{x}_k^T \check{P}_k^{-1} x_k. \tag{9.20}
$$

整理(取系数并转置)得

$$
\hat{P}_k^{-1} \hat{x}_k = C_k^T Q^{-1} z_k + \check{P}_k^{-1} \check{x}_k. \tag{9.21}
$$

两侧乘以$\hat{P}_k$并代入式(9.17)，得

$$
\hat{x}_k = \hat{P}_k C_k^T Q^{-1} z_k + \hat{P}_k \check{P}_k^{-1}\check{x}_k \tag{9.22}
$$

$$
\qquad \qquad \qquad \qquad \qquad = K z_k + (I - KC_k)\check{x}_k = \check{x}_k + K(z_k - C_k \check{x}_k). \tag{9.23}
$$

于是我们又得到了后验均值得表达。总而言之，上面得两个步骤可以归纳为“预测”和“更新”(Update)两个步骤：

<div style="border: 1px solid black;">
1. 预测：

$$
\check{x}_k = A_k \check{x}_{k-1} + u_k, \quad \check{P}_k = A_k \hat{P}_{k-1} A_k^T + R. \tag{9.24}
$$

2. 更新：先计算$K$，它又称为卡尔曼增益。

$$
K = \check{P}_k C_k^T(C_k \check{P}_k C_k^T + Q_k)^{-1}. \tag{9.25}
$$
然后计算后验概率的分布。

$$
\begin{array}{l}
    \hat{x}_k = \check{x}_k + K(z_k - C_k \check{x}_k) \\
    \hat{P}_k = (I - K C_k)\check{P}_k.
\end{array}. \tag{9.26}
$$
</div>

至此，我们推导了经典的卡尔曼滤波器的整个过程。事实上，卡尔曼滤波器有若干种推导方式，而我们使用的是从概率角度出发的最大后验概率估计的方式。我们看到，在线性高斯系统种，卡尔曼滤波器构成了该系统中的最大后验概率估计。而且，由于高斯分布经过线性变换后服从高斯分布，所以整个过程中我们没有进行任何的近似。可以说，卡尔曼滤波器构成了线性系统的最优无偏估计。

### 9.1.3 非线性系统和EKF

在理解了卡尔曼滤波之后，必须澄清一点：SLAM中的运动方程和观测方程通常是非线性函数，尤其是视觉SLAM中的相机模型，需要使用相机内参模型及李代数表示的位姿，更不可能是一个线性系统。一个高斯分布，经过非线性变换后，往往不再是高斯分布，所以在非线性系统中，必须取一定的近似，将一个非高斯分布近似成高斯分布。

我们希望把卡尔曼滤波器的结果拓展到非线性系统中，称为扩展卡尔曼滤波器。通常的做法是，在某个点附近考虑运动方程及观测方程的一阶泰勒展开，只保留一阶项，即线性的部分，然后按照线性系统进行推导。令$k-1$时刻的均值与协方差矩阵为$\hat{x}_{k-1},\hat{P}_{k-1}$。在$k$时刻，把运动方程和观测方程在$\hat{x}_{k-1},\hat{P}_{k-1}$处进行<B>线性化</B>(相当于一阶泰勒展开)，有

$$
x_k \approx f(\hat{x}_{k-1}, u_k) + \left. \frac{\partial f}{\partial x_{k-1}} \right |_{\hat{x}_{k-1}} (x_{k-1} - \hat{x}_{k-1}) + w_k. \tag{9.27}
$$

记这里的偏导数为

$$
F = \left. \frac{\partial f}{\partial x_{k-1}} \right |_{\hat{x}_{k-1}} . \tag{9.28}
$$

同样，对于观测方程，亦有

$$
z_k \approx h(\check{x}_k) + \left. \frac{\partial h}{\partial x_k} \right|_{\check{x}_k}(x_k - \check{x}_k) + n_k. \tag{9.29}
$$

记这里的偏导数为

$$
H = \left. \frac{\partial h}{\partial x_k} \right|_{\check{x}_k}. \tag{9.30}
$$

那么，在<B>预测</B>步骤中，根据运动方程有

$$
P(x_k|x_0,u_{1:k},z_{0:k-1}) = N(f(\hat{x}_{k-1},u_k), F\hat{P}_{k-1}F^T + R_k). \tag{9.31}
$$

这些推导和卡尔曼滤波是十分相似的。为方便表述，记这里的先验和协方差的均值为

$$
\check{x}_k = f(\hat{x}_{k-1}, u_k), \quad \check{P}_k = F\hat{P}_{k-1}F^T + R_k. \tag{9.32}
$$

然后，考虑在观测中我们有

$$
P(z_k|x_k) = N(h(\check{x}_k) + H(x_k - \check{x}_k). Q_k). \tag{9.33}
$$

最后，根据最开始的贝叶斯展开式，可以推导出$x_k$的后验概率形式。我们略去中间的推导过程，只介绍其结果。简而言之，先定义一个<B>卡尔曼增益$K_k$</B>：

$$
K_k = \check{P}_k H^T (H \check{P}_k H^T + Q_k)^{-1}. \tag{9.34}
$$

在卡尔曼增益的基础上，后验概率的形式为

$$
\hat{x}_k = \check{x}_k + K_k(z_k - h(\check{x}_k)), \hat{P}_k = (I - K_k H) \check{P}_k. \tag{9.35}
$$

卡尔曼滤波器给出了在线性化之后状态变量分布的变化过程。在线性系统和高斯噪声下，卡尔曼滤波器给出了无偏最优估计。而在SLAM这种非线性的情况下，它给出了单词线性近似下的最大后验估计。

### 9.1.4 EKF的讨论

EKF以形式简单、应用广泛著称。当想要在某段时间内估计某个不确定量时，首先想到的就是EKF。在早期的SLAM中，EKF占据了很长一段时间的主导地位，研究者们讨论了各种各样的滤波器在SLAM中的应用，如IF(信息滤波器)、IKF(Iterated KF)、UKF(Unscented KF)和例子滤波器、SWF(Sliding Window Filter)，或者用分治法等思路改进EKF的效率。时至今日，尽管我们认识到非线性优化比滤波器占有明显的优势，但是在计算资源受限，或待估计量比较简单的场合，EKF仍不失为一种有效的方式。

EKF有哪些局限性？

1. 滤波器方法在一定程度上假设了<B>马尔可夫性</B>，也就是$k$时刻的状态只与$k-1$时刻相关，而与$k-1$之前的状态和观测都无关。这有点像是在视觉里程计中只考虑相邻两帧的关系。如果当前帧确实与很久之前的数据有关(例如回环)，那么滤波器会难以处理。

而非线性优化方法则倾向于使用所有的历史数据。它不光考虑邻近时刻的特征点与轨迹关系，更会把很久之前的状态也考虑进来，称为全体时间上的SLAM(Full-SLAM)。在这种意义下，非线性优化方法使用了更多信息，当然也需要更多的计算。

2. 与第6讲介绍的优化方法相比，EKF滤波器仅在$\hat{x}_{k-1}$处做了<B>一次</B>线性化，就直接根据这次线性化的结果，把后验概率给算了出来。这相当于在说，我们认为<B>该点处的线性化近似在后验概率处仍然是有效的</B>。而实际上，当我们离工作点较远时，一阶泰勒展开并不一定能够近似整个函数，这取决于运动模型和观测模型的非线性情况。如果它们有强烈的非线性，那么线性近似就只在很小范围内成立，不能认为在很远的地方仍能使用线性来近似。这就是EKF的<B>非线性误差</B>，也就是它的主要问题所在。

在优化问题中，尽管我们也做一阶(最速下降)或二阶(高斯牛顿法或列文伯格-马奈尔特方法)的近似，但每迭代一次，状态估计发生改变之后，我们会重新对新的估计点做泰勒展开，而不像EKF那样只在固定点上做一次泰勒展开。这就使得优化的方法适用范围更广，在状态变化较大时也能适用。所以大体来说，可以粗略地认为<B>EKF仅是优化中的一次迭代</B>。

3. 从程序是线上来说，EKF需要存储状态量的均值和方差，并对它们进行维护和更新。如果把路标也放进状态，由于视觉SLAM中路标数量很大，则这个存储量是相当客观的，且与状态量呈平方增长(因为要存储协方差矩阵)。因此，普遍认为EKF SLAM不适用于大型场景。
4. EKF等滤波器方法没有异常检测机制，导致系统在存在异常值的时候很容易发散。而在视觉SLAM中，异常值却是很常见的：无论特征匹配还是光流法，都容易追踪或匹配到错误的点。没有异常值检测机制会让系统在实用中非常不稳定。

由于EKF存在这些明显的缺点，通常认为，在同等计算量的情况下，非线性优化能取得更好得效果。这里“更好”是指精度和鲁棒性同时达到更好的意思。下面讨论以非线性优化为主的后端，主要介绍图优化，并用g2o和Ceres演示后端优化。

---

## 9.2 BA与图优化

[Chapter9.2](./subChapter/Chapter9.2.md)


### 小结

本节重点介绍了BA中的稀疏性问题。不过，实践中，多数软件库已经为我们实现了细节操作，而我们要做的主要是构造BA问题，设置Schur消元，然后调用稠密或者稀疏矩阵求解器对变量进行优化。

---

## 9.3 实践：Ceres BA

[Chapter9.3](./subChapter/Chapter9.3.md)

---

## 9.4 实践：g2o求解BA

[Chapter9.4](./subChapter/Chapter9.4.md)

---

## 9.5 小结

本节比较深入地探讨了状态估计问题与图优化的求解。我们看到在经典模型中SLAM可以看成状态估计问题，如果我们假设了马尔可夫性，只考虑当前状态，则得到以EKF为代表的滤波器模型。如若不然，也可以考虑所有的运动和观测，它们构成一个最小二乘问题。在只有观测方程的情况下，这个问题称为BA，并可利用非线性优化方法求解。我们仔细讨论了求解过程中的稀疏问题，指出了该问题与图优化之间的联系。最后，我们演示了如何使用g2o和Ceres库求解同一个优化问题。